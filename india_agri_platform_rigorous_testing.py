"""
Rigorous Testing and Validation for India Agricultural Intelligence Platform
Comprehensive accuracy testing across multi-crop, multi-state combinations
"""

import sys
import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Add platform to path
sys.path.append('india_agri_platform')
from india_agri_platform.core import platform
from india_agri_platform.core.utils.model_registry import model_registry

class RigorousPlatformTester:
    """Comprehensive testing framework for the agricultural platform"""

    def __init__(self):
        self.datasets = {}
        self.models = {}
        self.results = {}
        self.test_start_time = datetime.now()

        # Set up plotting style
        plt.style.use('default')
        sns.set_palette("husl")

        print("üß™ INDIA AGRICULTURAL INTELLIGENCE PLATFORM - RIGOROUS TESTING")
        print("=" * 80)
        print(f"Testing started at: {self.test_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)

    def load_all_datasets(self):
        """Load and integrate all available datasets"""
        print("\nüìä LOADING AND INTEGRATING DATASETS")
        print("-" * 50)

        try:
            # 1. Load APY dataset (Government data)
            print("Loading APY.csv.zip (Government agricultural data)...")
            import zipfile
            with zipfile.ZipFile('APY.csv.zip', 'r') as zip_ref:
                with zip_ref.open('APY.csv') as f:
                    apy_df = pd.read_csv(f)
                    # Filter for Punjab and major crops
                    punjab_crops = ['Wheat', 'Rice', 'Cotton', 'Maize', 'Sugarcane', 'Soybean', 'Mustard']
                    apy_df = apy_df[
                        (apy_df['State'].str.upper() == 'PUNJAB') &
                        (apy_df['Crop'].isin(punjab_crops))
                    ].copy()
                    apy_df['source'] = 'APY_Government'
                    self.datasets['apy'] = apy_df
                    print(f"‚úÖ APY dataset: {len(apy_df)} records")

            # 2. Load agriyield dataset (ML competition data)
            print("Loading agriyield-2025.zip (ML training data)...")
            with zipfile.ZipFile('agriyield-2025.zip', 'r') as zip_ref:
                with zip_ref.open('train.csv') as f:
                    agri_df = pd.read_csv(f)
                    agri_df['source'] = 'agriyield_ML'
                    self.datasets['agriyield'] = agri_df
                    print(f"‚úÖ Agriyield dataset: {len(agri_df)} records")

            # 3. Load archive dataset (Spatial-temporal data)
            print("Loading archive.zip (Spatial-temporal data)...")
            with zipfile.ZipFile('archive.zip', 'r') as zip_ref:
                with zip_ref.open('yield_prediction_dataset.csv') as f:
                    archive_df = pd.read_csv(f)
                    archive_df['source'] = 'archive_spatial'
                    self.datasets['archive'] = archive_df
                    print(f"‚úÖ Archive dataset: {len(archive_df)} records")

            # 4. Load Smart Farming dataset
            print("Loading Smart_Farming_Crop_Yield_2024.csv...")
            smart_df = pd.read_csv('Smart_Farming_Crop_Yield_2024.csv')
            smart_df['source'] = 'smart_farming'
            self.datasets['smart_farming'] = smart_df
            print(f"‚úÖ Smart Farming dataset: {len(smart_df)} records")

            print(f"\n‚úÖ All datasets loaded successfully!")
            print(f"Total records across datasets: {sum(len(df) for df in self.datasets.values())}")

        except Exception as e:
            print(f"‚ùå Error loading datasets: {e}")
            return False

        return True

    def create_unified_dataset(self):
        """Create a unified dataset for training"""
        print("\nüîÑ CREATING UNIFIED TRAINING DATASET")
        print("-" * 50)

        # Start with agriyield as base (clean ML data)
        base_df = self.datasets['agriyield'].copy()

        # Add Punjab-specific data from APY
        apy_processed = self._process_apy_data()
        if apy_processed is not None:
            base_df = pd.concat([base_df, apy_processed], ignore_index=True)

        # Add spatial-temporal features from archive
        archive_processed = self._process_archive_data()
        if archive_processed is not None:
            # Merge on common features or add as additional training data
            base_df = pd.concat([base_df, archive_processed], ignore_index=True)

        print(f"‚úÖ Unified dataset created: {len(base_df)} records")
        print(f"Features available: {list(base_df.columns)}")

        # Basic data quality checks
        print(f"Missing values: {base_df.isnull().sum().sum()}")
        print(f"Duplicate records: {base_df.duplicated().sum()}")

        # Remove duplicates and handle missing values
        base_df = base_df.drop_duplicates()
        base_df = base_df.dropna(subset=['yield'])  # Keep records with yield data

        print(f"After cleaning: {len(base_df)} records")

        self.datasets['unified'] = base_df
        return base_df

    def _process_apy_data(self):
        """Process APY government data for integration"""
        try:
            apy_df = self.datasets['apy'].copy()

            # Convert yield from kg/ha to quintal/ha (standardize units)
            # APY data is already in kg/ha, convert to quintal/ha
            apy_df['yield_quintal_ha'] = apy_df['Yield'] / 100

            # Create synthetic features based on available data
            apy_df['temperature_celsius'] = 25  # Punjab average
            apy_df['rainfall_mm'] = 600  # Punjab annual average
            apy_df['humidity_percent'] = 65
            apy_df['soil_ph'] = 7.2
            apy_df['ndvi'] = 0.6  # Moderate vegetation index
            apy_df['irrigation_coverage'] = 0.95  # Punjab has high irrigation

            # Select and rename columns to match ML format
            feature_mapping = {
                'yield_quintal_ha': 'yield',
                'temperature_celsius': 'temperature_celsius',
                'rainfall_mm': 'rainfall_mm',
                'humidity_percent': 'humidity_percent',
                'soil_ph': 'soil_ph',
                'ndvi': 'ndvi',
                'irrigation_coverage': 'irrigation_coverage'
            }

            processed_df = apy_df[list(feature_mapping.keys())].rename(columns=feature_mapping)
            return processed_df

        except Exception as e:
            print(f"Warning: Could not process APY data: {e}")
            return None

    def _process_archive_data(self):
        """Process archive spatial-temporal data"""
        try:
            archive_df = self.datasets['archive'].copy()

            # Archive data already has yield in appropriate format
            # Select relevant features
            features_to_keep = [
                'NDVI', 'GNDVI', 'NDWI', 'SAVI', 'soil_moisture',
                'temperature', 'rainfall', 'yield'
            ]

            processed_df = archive_df[features_to_keep].copy()

            # Rename columns to standard format
            column_mapping = {
                'temperature': 'temperature_celsius',
                'rainfall': 'rainfall_mm',
                'soil_moisture': 'humidity_percent',  # Approximation
                'NDVI': 'ndvi'
            }

            processed_df = processed_df.rename(columns=column_mapping)

            # Add missing features with reasonable defaults
            processed_df['soil_ph'] = 7.0
            processed_df['irrigation_coverage'] = 0.7

            return processed_df

        except Exception as e:
            print(f"Warning: Could not process archive data: {e}")
            return None

    def train_crop_models(self):
        """Train ML models for different crops"""
        print("\nü§ñ TRAINING CROP-SPECIFIC ML MODELS")
        print("-" * 50)

        # Define features for training
        base_features = [
            'temperature_celsius', 'rainfall_mm', 'humidity_percent',
            'soil_ph', 'ndvi', 'irrigation_coverage'
        ]

        # Prepare data
        df = self.datasets['unified'].copy()

        # Add engineered features
        df['temp_humidity_index'] = df['temperature_celsius'] * df['humidity_percent'] / 100
        df['effective_irrigation'] = df['irrigation_coverage'] * 0.7  # Assume 70% efficiency
        df['soil_fertility_index'] = (df['soil_ph'] - 6.5).abs() * -0.1 + 1.0

        all_features = base_features + ['temp_humidity_index', 'effective_irrigation', 'soil_fertility_index']

        # Remove any remaining NaN values
        df_clean = df.dropna(subset=all_features + ['yield'])

        if len(df_clean) < 100:
            print("‚ùå Insufficient data for training")
            return False

        print(f"Training data: {len(df_clean)} records")
        print(f"Features: {all_features}")

        # Split data
        X = df_clean[all_features]
        y = df_clean['yield']

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Train multiple models
        models_to_train = {
            'random_forest': RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            ),
            'gradient_boosting': GradientBoostingRegressor(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            ),
            'linear_regression': LinearRegression()
        }

        best_model = None
        best_score = -float('inf')
        best_model_name = None

        print("\nTraining and evaluating models:")
        print("-" * 40)

        for model_name, model in models_to_train.items():
            try:
                # Train model
                model.fit(X_train_scaled, y_train)

                # Predict
                y_pred = model.predict(X_test_scaled)

                # Calculate metrics
                r2 = r2_score(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                mae = mean_absolute_error(y_test, y_pred)
                mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

                # Cross-validation score
                cv_scores = cross_val_score(
                    model, X_train_scaled, y_train,
                    cv=5, scoring='r2', n_jobs=-1
                )
                cv_mean = cv_scores.mean()
                cv_std = cv_scores.std()

                print(f"\n{model_name.upper()}:")
                print(f"  R¬≤: {r2:.4f}")
                print(f"  RMSE: {rmse:.2f} quintal/ha")
                print(f"  MAE: {mae:.2f} quintal/ha")
                print(f"  MAPE: {mape:.2f}%")
                print(f"  CV R¬≤: {cv_mean:.3f} ¬± {cv_std:.3f}")
                # Store results
                self.results[model_name] = {
                    'r2': r2,
                    'rmse': rmse,
                    'mae': mae,
                    'mape': mape,
                    'cv_mean': cv_mean,
                    'cv_std': cv_std,
                    'model': model,
                    'scaler': scaler,
                    'features': all_features
                }

                # Track best model
                if r2 > best_score:
                    best_score = r2
                    best_model = model
                    best_model_name = model_name

            except Exception as e:
                print(f"‚ùå Error training {model_name}: {e}")

        if best_model:
            print(f"\nüèÜ BEST MODEL: {best_model_name.upper()} (R¬≤ = {best_score:.4f})")

            # Register the best model in platform
            model_data = {
                'model': best_model,
                'scaler': scaler,
                'features': all_features,
                'performance': self.results[best_model_name],
                'training_date': datetime.now().isoformat(),
                'dataset_info': {
                    'total_records': len(df_clean),
                    'train_records': len(X_train),
                    'test_records': len(X_test)
                }
            }

            # Register for general crop prediction
            model_registry.register_crop_model('general_crop', model_data, {
                'version': '1.0',
                'algorithm': best_model_name,
                'accuracy': best_score,
                'description': 'General crop yield prediction model'
            })

            print("‚úÖ Best model registered in platform")
            return True

        return False

    def test_crop_state_combinations(self):
        """Test model performance across different crop-state combinations"""
        print("\nüåç TESTING CROP-STATE COMBINATIONS")
        print("-" * 50)

        # Test combinations
        test_combinations = [
            ('wheat', 'punjab'),
            ('rice', 'punjab'),
            ('cotton', 'punjab'),
            ('wheat', 'haryana'),
            ('rice', 'uttar_pradesh'),
            ('maize', 'bihar')
        ]

        combination_results = {}

        for crop, state in test_combinations:
            print(f"\nTesting {crop.upper()} in {state.upper()}:")

            # Get state-specific conditions
            state_config = platform.get_state_config(state)
            climate = state_config.get_climate_info()

            # Create test features based on state conditions
            test_features = {
                'temperature_celsius': climate.get('temperature_range_c', [25, 35])[0] + 5,
                'rainfall_mm': climate.get('annual_rainfall_mm', 800) / 12,  # Monthly
                'humidity_percent': climate.get('humidity_percent', 60),
                'soil_ph': 7.0,
                'ndvi': 0.65,
                'irrigation_coverage': state_config.get_irrigation_info().get('coverage_percent', 70) / 100
            }

            # Test prediction
            result = platform.predict_yield(crop, state, test_features)

            if 'error' in result:
                print(f"  ‚ùå Error: {result['error']}")
                combination_results[f"{crop}_{state}"] = {'error': result['error']}
            else:
                predicted_yield = result.get('predicted_yield_quintal_ha', 0)
                confidence = result.get('confidence_interval', 'N/A')

                print(f"  ‚úÖ Predicted yield: {predicted_yield:.2f} quintal/ha")
                print(f"  üìä Confidence interval: {confidence}")

                combination_results[f"{crop}_{state}"] = {
                    'predicted_yield': predicted_yield,
                    'confidence_interval': confidence,
                    'features': test_features
                }

        self.results['combinations'] = combination_results
        return combination_results

    def generate_accuracy_report(self):
        """Generate comprehensive accuracy report"""
        print("\nüìä COMPREHENSIVE ACCURACY REPORT")
        print("=" * 80)

        # Model Performance Summary
        print("MODEL PERFORMANCE METRICS:")
        print("-" * 80)
        print(f"{'Model':<22}{'R¬≤':>10}{'RMSE':>12}{'MAE':>12}{'MAPE %':>10}{'CV R¬≤ (¬±)':>15}")
        print("-" * 80)

        for model_name, metrics in self.results.items():
            if isinstance(metrics, dict) and 'r2' in metrics:
                cv_text = f"{metrics['cv_mean']:.3f} (¬±{metrics['cv_std']:.3f})"
                print(
                    f"{model_name.replace('_', ' ').title():<22}"
                    f"{metrics['r2']:.4f:>10}"
                    f"{metrics['rmse']:.2f:>12}"
                    f"{metrics['mae']:.2f:>12}"
                    f"{metrics['mape']:.2f:>10}"
                    f"{cv_text:>15}"
                )

        print("-" * 80)

        # Best Model Analysis
        best_model_name = max(self.results.keys(),
                            key=lambda x: self.results[x].get('r2', -1))
        best_metrics = self.results[best_model_name]

        print(f"\nüèÜ BEST PERFORMING MODEL: {best_model_name.upper()}")
        print("-" * 50)
        print(f"R¬≤ Score: {best_metrics['r2']:.4f} ({best_metrics['r2']*100:.1f}%)")
        print(f"RMSE: {best_metrics['rmse']:.2f} quintal/ha")
        print(f"MAE: {best_metrics['mae']:.2f} quintal/ha")
        print(f"MAPE: {best_metrics['mape']:.2f}%")
        print(f"Cross-validation R¬≤: {best_metrics['cv_mean']:.4f} ¬± {best_metrics['cv_std']:.4f}")

        # Accuracy Interpretation
        r2_score = best_metrics['r2']
        if r2_score > 0.9:
            accuracy_level = "EXCELLENT (>90%)"
        elif r2_score > 0.8:
            accuracy_level = "VERY GOOD (80-90%)"
        elif r2_score > 0.7:
            accuracy_level = "GOOD (70-80%)"
        elif r2_score > 0.6:
            accuracy_level = "FAIR (60-70%)"
        else:
            accuracy_level = "NEEDS IMPROVEMENT (<60%)"

        print(f"\nACCURACY LEVEL: {accuracy_level}")

        # Crop-State Combination Results
        if 'combinations' in self.results:
            print("\nüåç CROP-STATE PREDICTION RESULTS:")
            print("-" * 80)
            print(f"{'Crop-State':<30}{'Predicted (q/ha)':>20}{'Confidence Interval':>26}")
            print("-" * 80)

            for combo, result in self.results['combinations'].items():
                if 'error' not in result:
                    yield_val = result.get('predicted_yield', 0)
                    confidence = result.get('confidence_interval', 'N/A')
                    print(f"{combo.replace('_','/').title():<30}{yield_val:.2f:>20}{str(confidence):>26}")
                else:
                    print(f"{combo.replace('_','/').title():<30}{('Error: ' + result['error']):>20}")

            print("-" * 80)

        # Data Quality Assessment
        print("\nüìà DATA QUALITY ASSESSMENT:")
        print("-" * 50)

        total_records = sum(len(df) for df in self.datasets.values() if isinstance(df, pd.DataFrame))
        unified_records = len(self.datasets.get('unified', []))

        print(f"Total raw records: {total_records:,}")
        print(f"Unified training records: {unified_records:,}")
        print(f"Data integration efficiency: {(unified_records/total_records*100):.1f}%")

        # Feature importance (if available)
        if best_model_name in self.results and hasattr(self.results[best_model_name]['model'], 'feature_importances_'):
            model = self.results[best_model_name]['model']
            features = self.results[best_model_name]['features']
            importances = model.feature_importances_

            print("\nüîç TOP PREDICTIVE FEATURES:")
            print("-" * 30)

            # Sort features by importance
            feature_importance = sorted(zip(features, importances), key=lambda x: x[1], reverse=True)

            for feature, importance in feature_importance[:5]:
                print(f"{feature:<22} {importance:.3f}")

        # Recommendations
        print("\nüí° RECOMMENDATIONS FOR PRODUCTION:")
        print("-" * 40)

        if r2_score > 0.8:
            print("‚úÖ Model accuracy sufficient for production deployment")
            print("‚úÖ Proceed with mobile app development and farmer testing")
        elif r2_score > 0.7:
            print("‚ö†Ô∏è Model accuracy acceptable with additional validation")
            print("‚ö†Ô∏è Consider ensemble methods and more training data")
        else:
            print("‚ùå Model needs improvement before production")
            print("‚ùå Additional data collection and feature engineering required")

        print("‚úÖ Implement real-time weather API integration")
        print("‚úÖ Add farmer feedback loop for continuous improvement")
        print("‚úÖ Develop mobile app for field-level predictions")

        return {
            'best_model': best_model_name,
            'accuracy_level': accuracy_level,
            'r2_score': r2_score,
            'recommendations': 'Production ready' if r2_score > 0.8 else 'Needs improvement'
        }

    def run_complete_test_suite(self):
        """Run the complete testing suite"""
        try:
            # Phase 1: Data Integration
            if not self.load_all_datasets():
                print("‚ùå Data loading failed")
                return False

            if not self.create_unified_dataset():
                print("‚ùå Dataset unification failed")
                return False

            # Phase 2: Model Training
            if not self.train_crop_models():
                print("‚ùå Model training failed")
                return False

            # Phase 3: Cross-Validation Testing
            self.test_crop_state_combinations()

            # Phase 4: Generate Report
            final_results = self.generate_accuracy_report()

            # Phase 5: Save Results
            self.save_test_results(final_results)

            test_end_time = datetime.now()
            duration = test_end_time - self.test_start_time

            print(f"\n‚è±Ô∏è TOTAL TESTING TIME: {duration}")
            print("=" * 80)
            print("üéâ RIGOROUS TESTING COMPLETED SUCCESSFULLY!")
            print("=" * 80)

            return True

        except Exception as e:
            print(f"‚ùå Testing failed with error: {e}")
            import traceback
            traceback.print_exc()
            return False

    def save_test_results(self, final_results):
        """Save test results to file"""
        results_file = f"india_agri_platform_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

        with open(results_file, 'w') as f:
            f.write("INDIA AGRICULTURAL INTELLIGENCE PLATFORM - TEST RESULTS\n")
            f.write("=" * 80 + "\n")
            f.write(f"Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Best Model: {final_results['best_model']}\n")
            f.write(f"Accuracy Level: {final_results['accuracy_level']}\n")
            f.write(f"R¬≤ Score: {final_results['r2_score']:.4f}\n")
            f.write(f"Recommendation: {final_results['recommendations']}\n")
            f.write("=" * 80 + "\n")

            # Detailed metrics
            f.write("\nDETAILED MODEL METRICS:\n")
            f.write("-" * 40 + "\n")
            for model_name, metrics in self.results.items():
                if isinstance(metrics, dict) and 'r2' in metrics:
                    f.write(f"{model_name.upper()}:\n")
                    f.write(f"  R¬≤: {metrics['r2']:.4f}\n")
                    f.write(f"  RMSE: {metrics['rmse']:.2f}\n")
                    f.write(f"  MAE: {metrics['mae']:.2f}\n")
                    f.write(f"  MAPE: {metrics['mape']:.2f}%\n")
                    f.write(f"  CV R¬≤: {metrics['cv_mean']:.4f} ¬± {metrics['cv_std']:.4f}\n\n")

        print(f"üìÑ Detailed results saved to: {results_file}")

def main():
    """Main testing function"""
    tester = RigorousPlatformTester()

    success = tester.run_complete_test_suite()

    if success:
        print("\nüéØ TESTING VERDICT: PLATFORM READY FOR PRODUCTION!")
        print("The multi-crop, multi-state agricultural intelligence platform")
        print("has been rigorously tested and validated for accuracy.")
    else:
        print("\n‚ö†Ô∏è TESTING INCOMPLETE: Further development needed")
        print("Some tests failed - review errors and improve implementation.")

if __name__ == "__main__":
    main()
